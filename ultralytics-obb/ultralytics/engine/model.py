# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
# Ultralytics å¼€æºåè®® AGPL-3.0 - https://ultralytics.com/license

from __future__ import annotations
import inspect
from pathlib import Path
from typing import Any

import numpy as np
import torch
from PIL import Image

from ultralytics.cfg import TASK2DATA, get_cfg, get_save_dir
from ultralytics.engine.results import Results
from ultralytics.nn.tasks import guess_model_task, load_checkpoint, yaml_model_load
from ultralytics.utils import (
    ARGV,
    ASSETS,
    DEFAULT_CFG_DICT,
    LOGGER,
    RANK,
    SETTINGS,
    YAML,
    callbacks,
    checks,
)


class Model(torch.nn.Module):
    """
    YOLO æ¨¡å‹çš„åŸºç¡€ç±»ï¼Œä¸ºä¸åŒç±»å‹çš„æ¨¡å‹æä¾›ç»Ÿä¸€æ¥å£ã€‚

    è¯¥ç±»å°è£…äº† YOLO ç³»åˆ—æ¨¡å‹çš„é€šç”¨åŠŸèƒ½ï¼ŒåŒ…æ‹¬è®­ç»ƒã€éªŒè¯ã€æ¨ç†ã€å¯¼å‡ºå’ŒåŸºå‡†æµ‹è¯•ç­‰ã€‚
    å®ƒæ”¯æŒä»æœ¬åœ°æ–‡ä»¶ã€Ultralytics HUB äº‘ç«¯æˆ– Triton Server åŠ è½½æ¨¡å‹ï¼Œå¹¶è‡ªåŠ¨é€‚é…ä»»åŠ¡ç±»å‹ã€‚

    ä¸»è¦å±æ€§ï¼š
        callbacks: å›è°ƒå‡½æ•°å­—å…¸ï¼Œç”¨äºåœ¨æ¨¡å‹ç”Ÿå‘½å‘¨æœŸä¸­è§¦å‘è‡ªå®šä¹‰äº‹ä»¶ã€‚
        predictor: ç”¨äºæ‰§è¡Œæ¨ç†çš„é¢„æµ‹å™¨å¯¹è±¡ã€‚
        model: å®é™…çš„ PyTorch æ¨¡å‹å®ä¾‹ã€‚
        trainer: è®­ç»ƒå™¨å¯¹è±¡ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒã€‚
        ckpt: å¦‚æœä» .pt æ–‡ä»¶åŠ è½½æ¨¡å‹ï¼Œåˆ™æ­¤å­—æ®µå­˜å‚¨æ£€æŸ¥ç‚¹å†…å®¹ã€‚
        cfg: è‹¥ä» .yaml æ–‡ä»¶åŠ è½½æ¨¡å‹ï¼Œåˆ™æ­¤å­—æ®µä¸ºæ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„ã€‚
        ckpt_path: æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ã€‚
        overrides: è®­ç»ƒ/æ¨ç†é…ç½®å‚æ•°çš„è¦†ç›–å­—å…¸ã€‚
        metrics: æœ€æ–°è®­ç»ƒæˆ–éªŒè¯æŒ‡æ ‡ã€‚
        session: è‹¥æ¨¡å‹æ¥è‡ª HUBï¼Œåˆ™ä¸ºå½“å‰çš„äº‘ç«¯è®­ç»ƒä¼šè¯ã€‚
        task: æ¨¡å‹ä»»åŠ¡ç±»å‹(æ£€æµ‹ã€åˆ†å‰²ã€åˆ†ç±»ã€å§¿æ€ä¼°è®¡ã€æ—‹è½¬æ¡†æ£€æµ‹ç­‰ï¼‰ã€‚
        model_name: æ¨¡å‹åç§°ã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics import YOLO
        >>> model = YOLO("yolo11n.pt")
        >>> results = model.predict("image.jpg")
        >>> model.train(data="coco8.yaml", epochs=3)
        >>> metrics = model.val()
        >>> model.export(format="onnx")
    """

    def __init__(
        self,
        model: str | Path | Model = "yolo11n.pt",
        task: str = None,
        verbose: bool = False,
    ) -> None:
        """
        åˆå§‹åŒ– YOLO æ¨¡å‹å®ä¾‹ã€‚

        æœ¬å‡½æ•°æ ¹æ®è¾“å…¥è·¯å¾„æˆ–æ¨¡å‹åç§°åŠ è½½ YOLO æ¨¡å‹ï¼Œæ”¯æŒæœ¬åœ°æ–‡ä»¶ã€Ultralytics HUB æ¨¡å‹å’Œ Triton Server æ¨¡å‹ã€‚
        åˆå§‹åŒ–åå¯ç›´æ¥è¿›è¡Œè®­ç»ƒã€æ¨ç†æˆ–å¯¼å‡ºæ“ä½œã€‚

        å‚æ•°ï¼š
            model: æ¨¡å‹è·¯å¾„æˆ–åç§°ï¼Œå¯ä¸º .pt æƒé‡æ–‡ä»¶ã€.yaml é…ç½®æ–‡ä»¶ã€HUB æ¨¡å‹ URL æˆ– Triton æ¨¡å‹ã€‚
            task: æ¨¡å‹ä»»åŠ¡ç±»å‹(å¯é€‰ï¼‰ï¼Œè‹¥æœªæŒ‡å®šåˆ™è‡ªåŠ¨æ¨æ–­ã€‚
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ã€‚

        å¼‚å¸¸ï¼š
            FileNotFoundError: æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ã€‚
            ValueError: æ–‡ä»¶æ ¼å¼ä¸å—æ”¯æŒã€‚
            ImportError: ç¼ºå°‘å¿…è¦ä¾èµ–ã€‚
        """
        if isinstance(model, Model):
            # è‹¥ä¼ å…¥çš„å‚æ•°å·²æ˜¯ Model å¯¹è±¡ï¼Œåˆ™ç›´æ¥å¤åˆ¶å…¶å±æ€§
            self.__dict__ = model.__dict__
            return

        super().__init__()
        self.callbacks = callbacks.get_default_callbacks()  # åˆå§‹åŒ–é»˜è®¤å›è°ƒ
        self.predictor = None  # é¢„æµ‹å™¨å¯¹è±¡
        self.model = None  # æ¨¡å‹æœ¬ä½“
        self.trainer = None  # è®­ç»ƒå™¨å¯¹è±¡
        self.ckpt = {}  # è‹¥ä» .pt åŠ è½½æ¨¡å‹ï¼Œåˆ™æ­¤å¤„ä¿å­˜æ£€æŸ¥ç‚¹å†…å®¹
        self.cfg = None  # è‹¥ä» .yaml åŠ è½½æ¨¡å‹ï¼Œåˆ™æ­¤å¤„ä¿å­˜é…ç½®è·¯å¾„
        self.ckpt_path = None  # æ£€æŸ¥ç‚¹è·¯å¾„
        self.overrides = {}  # è¦†ç›–å‚æ•°
        self.metrics = None  # æ€§èƒ½æŒ‡æ ‡
        self.session = None  # HUB ä¼šè¯
        self.task = task  # æ¨¡å‹ä»»åŠ¡ç±»å‹
        self.model_name = None  # æ¨¡å‹åç§°

        model = str(model).strip()

        # å¦‚æœæ˜¯ Ultralytics HUB æ¨¡å‹(å½¢å¦‚ https://hub.ultralytics.com/models/...ï¼‰
        if self.is_hub_model(model):
            from ultralytics.hub import HUBTrainingSession

            checks.check_requirements("hub-sdk>=0.0.12")  # ç¡®ä¿ hub-sdk å·²å®‰è£…
            session = HUBTrainingSession.create_session(model)
            model = session.model_file  # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
            if session.train_args:  # è‹¥ä¸º HUB è®­ç»ƒä»»åŠ¡
                self.session = session

        # å¦‚æœæ˜¯ Triton Server æ¨¡å‹
        elif self.is_triton_model(model):
            self.model_name = self.model = model
            self.overrides["task"] = task or "detect"  # é»˜è®¤æ£€æµ‹ä»»åŠ¡
            return

        # å¯ç”¨ç¡®å®šæ€§ CUDA è¡Œä¸ºï¼Œé¿å…è¿è¡Œæ—¶è­¦å‘Š
        __import__("os").environ["CUBLAS_WORKSPACE_CONFIG"] = ":4096:8"

        # è‹¥ä»¥ YAML æ–‡ä»¶ç»“å°¾ï¼Œåˆ™åˆ›å»ºæ–°æ¨¡å‹
        if str(model).endswith((".yaml", ".yml")):
            self._new(model, task=task, verbose=verbose)
        else:
            # å¦åˆ™åŠ è½½å·²è®­ç»ƒæ¨¡å‹
            self._load(model, task=task)

        # åˆ é™¤çˆ¶ç±»çš„ training å±æ€§ï¼Œä»¥ä¾¿ç›´æ¥è®¿é—® self.model.training
        del self.training

    def __call__(
        self,
        source: str | Path | int | Image.Image | list | tuple | np.ndarray | torch.Tensor = None,
        stream: bool = False,
        **kwargs: Any,
    ) -> list:
        """
        å…è®¸æ¨¡å‹å¯¹è±¡è¢«ç›´æ¥è°ƒç”¨ä»¥æ‰§è¡Œæ¨ç†ã€‚

        è¯¥æ–¹æ³•ç­‰ä»·äº predict()ï¼Œå¯ç›´æ¥é€šè¿‡ `model(source)` è°ƒç”¨ã€‚

        å‚æ•°ï¼š
            source: è¾“å…¥æºï¼Œå¯ä¸ºå›¾ç‰‡è·¯å¾„ã€PIL å›¾åƒã€numpy æ•°ç»„ã€torch.Tensor æˆ–è§†é¢‘æµç­‰ã€‚
            stream: æ˜¯å¦ä»¥æµæ¨¡å¼æ¨ç†(è¿”å›ç”Ÿæˆå™¨ï¼‰ã€‚
            kwargs: ä¼ é€’ç»™ predict() çš„é¢å¤–å‚æ•°ã€‚

        è¿”å›ï¼š
            list[Results]: åŒ…å«æ¨ç†ç»“æœçš„å¯¹è±¡åˆ—è¡¨ã€‚
        """
        return self.predict(source, stream, **kwargs)

    @staticmethod
    def is_triton_model(model: str) -> bool:
        """
        åˆ¤æ–­ç»™å®šå­—ç¬¦ä¸²æ˜¯å¦ä¸º Triton Server æ¨¡å‹åœ°å€ã€‚

        å‚æ•°ï¼š
            model: å¾…æ£€æµ‹å­—ç¬¦ä¸²ã€‚

        è¿”å›ï¼š
            bool: è‹¥ä¸ºåˆæ³• Triton URL(http/grpcï¼‰ï¼Œè¿”å› Trueã€‚
        """
        from urllib.parse import urlsplit
        url = urlsplit(model)
        return url.netloc and url.path and url.scheme in {"http", "grpc"}

    @staticmethod
    def is_hub_model(model: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸º Ultralytics HUB æ¨¡å‹ã€‚

        å‚æ•°ï¼š
            model: æ¨¡å‹å­—ç¬¦ä¸²ã€‚

        è¿”å›ï¼š
            bool: è‹¥ä¸ºåˆæ³• HUB æ¨¡å‹ URLï¼Œè¿”å› Trueã€‚
        """
        from ultralytics.hub import HUB_WEB_ROOT
        return model.startswith(f"{HUB_WEB_ROOT}/models/")

    def _new(self, cfg: str, task=None, model=None, verbose=False) -> None:
        """
        åˆ›å»ºæ–°æ¨¡å‹ï¼Œå¹¶æ ¹æ®é…ç½®æ–‡ä»¶æ¨æ–­ä»»åŠ¡ç±»å‹ã€‚

        è¯¥å‡½æ•°ç”¨äºä» .yaml æ¨¡å‹å®šä¹‰æ–‡ä»¶åˆå§‹åŒ–æ¨¡å‹ç»“æ„ï¼Œæ”¯æŒè‡ªåŠ¨è¯†åˆ«ä»»åŠ¡ç±»å‹å¹¶åŠ è½½å¯¹åº”çš„ç½‘ç»œç»“æ„ã€‚

        å‚æ•°ï¼š
            cfg: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„(YAML æ ¼å¼ï¼‰ã€‚
            task: æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨æ¨æ–­ã€‚
            model: è‹¥ä¼ å…¥è‡ªå®šä¹‰æ¨¡å‹å®ä¾‹ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ã€‚
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ã€‚
        """
        cfg_dict = yaml_model_load(cfg)  # è¯»å– YAML é…ç½®
        self.cfg = cfg
        self.task = task or guess_model_task(cfg_dict)  # è‹¥æœªæŒ‡å®š taskï¼Œåˆ™æ ¹æ®é…ç½®æ¨æ–­

        # ä½¿ç”¨ _smart_load åŠ è½½ç›¸åº”ä»»åŠ¡çš„æ¨¡å‹ç±»å¹¶å®ä¾‹åŒ–
        self.model = (model or self._smart_load("model"))(cfg_dict, verbose=verbose and RANK == -1)
        self.overrides["model"] = self.cfg
        self.overrides["task"] = self.task

        # åˆå¹¶é»˜è®¤é…ç½®å’Œæ¨¡å‹å‚æ•°ï¼Œä¾¿äºå¯¼å‡º
        self.model.args = {**DEFAULT_CFG_DICT, **self.overrides}
        self.model.task = self.task
        self.model_name = cfg
    def _load(self, weights: str, task=None) -> None:
        """
        ä»æ£€æŸ¥ç‚¹æ–‡ä»¶åŠ è½½æ¨¡å‹æˆ–åˆå§‹åŒ–æƒé‡ã€‚

        è¯¥å‡½æ•°æ”¯æŒä» .pt æ£€æŸ¥ç‚¹æˆ–å…¶ä»–æƒé‡æ–‡ä»¶åŠ è½½æ¨¡å‹ï¼Œå¹¶è®¾ç½®ä»»åŠ¡ç±»å‹ä¸æ¨¡å‹å‚æ•°ã€‚

        å‚æ•°ï¼š
            weights: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ã€‚
            task: æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨æ¨æ–­ã€‚

        å¼‚å¸¸ï¼š
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨ã€‚
            ValueError: æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒã€‚
        """
        # è‹¥è¾“å…¥ä¸ºç½‘ç»œé“¾æ¥(HTTP / RTSP / RTMP ç­‰ï¼‰ï¼Œåˆ™å…ˆä¸‹è½½
        if weights.lower().startswith(("https://", "http://", "rtsp://", "rtmp://", "tcp://")):
            weights = checks.check_file(weights, download_dir=SETTINGS["weights_dir"])
        # æ£€æŸ¥æ–‡ä»¶åˆæ³•æ€§(è¡¥å…¨åç¼€ .ptï¼‰
        weights = checks.check_model_file_from_stem(weights)

        # è‹¥ä¸º PyTorch æ£€æŸ¥ç‚¹æ–‡ä»¶
        if str(weights).rpartition(".")[-1] == "pt":
            self.model, self.ckpt = load_checkpoint(weights)
            self.task = self.model.task
            self.overrides = self.model.args = self._reset_ckpt_args(self.model.args)
            self.ckpt_path = self.model.pt_path
        else:
            # å…¶ä»–ç±»å‹æ–‡ä»¶ç›´æ¥åŠ è½½
            weights = checks.check_file(weights)
            self.model, self.ckpt = weights, None
            self.task = task or guess_model_task(weights)
            self.ckpt_path = weights

        self.overrides["model"] = weights
        self.overrides["task"] = self.task
        self.model_name = weights

    def _check_is_pytorch_model(self) -> None:
        """
        æ£€æŸ¥å½“å‰æ¨¡å‹æ˜¯å¦ä¸º PyTorch æ¨¡å‹ã€‚

        è‹¥æ¨¡å‹ä¸æ˜¯ torch.nn.Module æˆ– .pt æ–‡ä»¶ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚
        æŸäº›æ“ä½œ(å¦‚è®­ç»ƒã€éªŒè¯ã€å¯¼å‡ºï¼‰ä»…åœ¨ PyTorch æ¨¡å‹ä¸‹å¯æ‰§è¡Œã€‚
        """
        pt_str = isinstance(self.model, (str, Path)) and str(self.model).rpartition(".")[-1] == "pt"
        pt_module = isinstance(self.model, torch.nn.Module)
        if not (pt_module or pt_str):
            raise TypeError(
                f"å½“å‰æ¨¡å‹ '{self.model}' ä¸æ˜¯æœ‰æ•ˆçš„ PyTorch æ¨¡å‹ã€‚ä»…æ”¯æŒ .pt æ–‡ä»¶æˆ– torch.nn.Module å¯¹è±¡ã€‚"
                f"ONNXã€TensorRT ç­‰å¯¼å‡ºæ ¼å¼ä»…å¯æ‰§è¡Œ predict/valï¼Œè€Œé train/exportã€‚"
            )

    def reset_weights(self) -> Model:
        """
        é‡ç½®æ¨¡å‹å‚æ•°ä¸ºåˆå§‹çŠ¶æ€ã€‚

        éå†æ¨¡å‹çš„æ‰€æœ‰æ¨¡å—ï¼Œå¦‚æœæ¨¡å—å­˜åœ¨ reset_parameters() æ–¹æ³•ï¼Œåˆ™æ‰§è¡Œé‡ç½®ã€‚
        åŒæ—¶ç¡®ä¿æ‰€æœ‰å‚æ•°çš„ requires_grad = Trueã€‚

        è¿”å›ï¼š
            selfï¼šé‡ç½®åçš„æ¨¡å‹å¯¹è±¡ã€‚
        """
        self._check_is_pytorch_model()
        for m in self.model.modules():
            if hasattr(m, "reset_parameters"):
                m.reset_parameters()
        for p in self.model.parameters():
            p.requires_grad = True
        return self

    def load(self, weights: str | Path = "yolo11n.pt") -> Model:
        """
        ä»æŒ‡å®šæƒé‡æ–‡ä»¶åŠ è½½å‚æ•°ã€‚

        å‚æ•°ï¼š
            weights: æƒé‡æ–‡ä»¶è·¯å¾„ã€‚

        è¿”å›ï¼š
            selfï¼šåŠ è½½æƒé‡åçš„æ¨¡å‹å¯¹è±¡ã€‚
        """
        self._check_is_pytorch_model()
        if isinstance(weights, (str, Path)):
            self.overrides["pretrained"] = weights
            weights, self.ckpt = load_checkpoint(weights)
        self.model.load(weights)
        return self

    def save(self, filename: str | Path = "saved_model.pt") -> None:
        """
        ä¿å­˜æ¨¡å‹å½“å‰çŠ¶æ€åˆ°æŒ‡å®šè·¯å¾„ã€‚

        å‚æ•°ï¼š
            filename: ä¿å­˜è·¯å¾„(é»˜è®¤ saved_model.ptï¼‰
        """
        self._check_is_pytorch_model()
        from copy import deepcopy
        from datetime import datetime
        from ultralytics import __version__

        updates = {
            "model": deepcopy(self.model).half() if isinstance(self.model, torch.nn.Module) else self.model,
            "date": datetime.now().isoformat(),
            "version": __version__,
            "license": "AGPL-3.0 License (https://ultralytics.com/license)",
            "docs": "https://docs.ultralytics.com",
        }
        torch.save({**self.ckpt, **updates}, filename)

    def info(self, detailed: bool = False, verbose: bool = True):
        """
        æ˜¾ç¤ºæ¨¡å‹ç»“æ„ä¿¡æ¯ã€‚

        å‚æ•°ï¼š
            detailed: è‹¥ä¸º Trueï¼Œæ˜¾ç¤ºè¯¦ç»†å±‚çº§å‚æ•°ä¿¡æ¯ã€‚
            verbose: è‹¥ä¸º Falseï¼Œè¿”å›ä¿¡æ¯å­—ç¬¦ä¸²åˆ—è¡¨è€Œéæ‰“å°è¾“å‡ºã€‚

        è¿”å›ï¼š
            æ¨¡å‹ç»“æ„ä¸å‚æ•°ä¿¡æ¯(è‹¥ verbose=Falseï¼‰ã€‚
        """
        self._check_is_pytorch_model()
        return self.model.info(detailed=detailed, verbose=verbose)

    def fuse(self) -> None:
        """
        å°† Conv2d ä¸ BatchNorm2d å±‚èåˆä»¥åŠ é€Ÿæ¨ç†ã€‚

        è¯¥è¿‡ç¨‹é€šè¿‡æŠ˜å  BN å‚æ•°(å‡å€¼ã€æ–¹å·®ã€æƒé‡ã€åç½®ï¼‰è¿›å·ç§¯å±‚ï¼Œ
        ä»è€Œå‡å°‘æ¨ç†æ—¶çš„è¿ç®—é‡ä¸æ˜¾å­˜è®¿é—®æ¬¡æ•°ã€‚
        """
        self._check_is_pytorch_model()
        self.model.fuse()

    def embed(
        self,
        source: str | Path | int | list | tuple | np.ndarray | torch.Tensor = None,
        stream: bool = False,
        **kwargs: Any,
    ) -> list:
        """
        åŸºäºè¾“å…¥æºç”Ÿæˆå›¾åƒåµŒå…¥ç‰¹å¾ã€‚

        å‚æ•°ï¼š
            source: è¾“å…¥æº(å›¾ç‰‡è·¯å¾„ã€PIL å›¾åƒã€numpy æ•°ç»„ç­‰ï¼‰ã€‚
            stream: æ˜¯å¦ä»¥æµæ–¹å¼å¤„ç†ã€‚
            kwargs: å…¶ä»–å¯é€‰å‚æ•°ã€‚

        è¿”å›ï¼š
            list[torch.Tensor]ï¼šç”Ÿæˆçš„å›¾åƒç‰¹å¾å¼ é‡ã€‚
        """
        if not kwargs.get("embed"):
            kwargs["embed"] = [len(self.model.model) - 2]  # é»˜è®¤å–å€’æ•°ç¬¬äºŒå±‚
        return self.predict(source, stream, **kwargs)

    def predict(
        self,
        source: str | Path | int | Image.Image | list | tuple | np.ndarray | torch.Tensor = None,
        stream: bool = False,
        predictor=None,
        **kwargs: Any,
    ) -> list[Results]:
        """
        æ‰§è¡Œæ¨ç†æ“ä½œã€‚

        å‚æ•°ï¼š
            source: è¾“å…¥æºï¼Œå¯ä¸ºæ–‡ä»¶è·¯å¾„ã€å›¾åƒæ•°ç»„æˆ–è§†é¢‘æµã€‚
            stream: æ˜¯å¦ä»¥æµæ¨¡å¼è¿”å›ç”Ÿæˆå™¨ã€‚
            predictor: è‡ªå®šä¹‰é¢„æµ‹å™¨å¯¹è±¡(å¯é€‰ï¼‰ã€‚
            kwargs: å…¶ä»–è‡ªå®šä¹‰æ¨ç†å‚æ•°ï¼Œå¦‚ confã€deviceã€half ç­‰ã€‚

        è¿”å›ï¼š
            list[Results]ï¼šæ¨ç†ç»“æœåˆ—è¡¨ã€‚
        """
        # è‹¥æœªæŒ‡å®šè¾“å…¥ï¼Œåˆ™é»˜è®¤ä½¿ç”¨ Ultralytics ç¤ºä¾‹å›¾ç‰‡
        if source is None:
            source = "https://ultralytics.com/images/boats.jpg" if self.task == "obb" else ASSETS
            LOGGER.warning(f"'source' æœªæŒ‡å®šï¼Œé»˜è®¤ä½¿ç”¨ {source}")

        # åˆ¤æ–­æ˜¯å¦ä»å‘½ä»¤è¡Œè°ƒç”¨
        is_cli = (ARGV[0].endswith("yolo") or ARGV[0].endswith("ultralytics")) and any(
            x in ARGV for x in ("predict", "track", "mode=predict", "mode=track")
        )

        # é»˜è®¤æ¨ç†å‚æ•°
        custom = {"conf": 0.25, "batch": 1, "save": is_cli, "mode": "predict", "rect": True}
        args = {**self.overrides, **custom, **kwargs}
        prompts = args.pop("prompts", None)  # ç”¨äº SAM æ¨¡å‹æç¤ºè¯

        # è‹¥ predictor æœªåˆå§‹åŒ–ï¼Œåˆ™åˆ›å»ºæ–°çš„é¢„æµ‹å™¨
        if not self.predictor:
            self.predictor = (predictor or self._smart_load("predictor"))(overrides=args, _callbacks=self.callbacks)
            self.predictor.setup_model(model=self.model, verbose=is_cli)
        else:
            # è‹¥å·²å­˜åœ¨é¢„æµ‹å™¨ï¼Œåˆ™ä»…æ›´æ–°å‚æ•°
            self.predictor.args = get_cfg(self.predictor.args, args)
            if "project" in args or "name" in args:
                self.predictor.save_dir = get_save_dir(self.predictor.args)

        # è‹¥ä¸º SAM æ¨¡å‹ï¼Œåˆ™åŠ è½½æç¤ºè¯
        if prompts and hasattr(self.predictor, "set_prompts"):
            self.predictor.set_prompts(prompts)

        # è¿”å›ç»“æœ
        if is_cli:
            return self.predictor.predict_cli(source=source)
        else:
            gen = self.predictor.stream_inference(source=source)
            return gen if stream else list(gen)

    def track(
        self,
        source: str | Path | int | list | tuple | np.ndarray | torch.Tensor = None,
        stream: bool = False,
        persist: bool = False,
        **kwargs: Any,
    ) -> list[Results]:
        """
        å¯¹è¾“å…¥æºè¿›è¡Œç›®æ ‡è·Ÿè¸ªã€‚

        è¯¥æ–¹æ³•ä½¿ç”¨æ³¨å†Œçš„è·Ÿè¸ªå™¨åœ¨è§†é¢‘ã€å®æ—¶æµæˆ–å›¾åƒåºåˆ—ä¸­è¿›è¡Œç›®æ ‡è·Ÿè¸ªã€‚
        æ”¯æŒå¤šç§è·Ÿè¸ªç®—æ³•(å¦‚ ByteTrackï¼‰ã€‚

        å‚æ•°ï¼š
            source: è¾“å…¥æº(æ–‡ä»¶è·¯å¾„ã€URLã€è§†é¢‘æµç­‰ï¼‰ã€‚
            stream: æ˜¯å¦ä»¥æµæ¨¡å¼è¿›è¡Œæ¨ç†ã€‚
            persist: æ˜¯å¦åœ¨å¤šæ¬¡è°ƒç”¨ä¸­ä¿ç•™è·Ÿè¸ªçŠ¶æ€ã€‚
            kwargs: å…¶ä»–è‡ªå®šä¹‰å‚æ•°ã€‚

        è¿”å›ï¼š
            list[Results]ï¼šåŒ…å«è·Ÿè¸ªç»“æœçš„ç»“æœå¯¹è±¡åˆ—è¡¨ã€‚
        """
        # è‹¥å½“å‰ predictor æœªæ³¨å†Œ trackerï¼Œåˆ™æ³¨å†Œ
        if not hasattr(self.predictor, "trackers"):
            from ultralytics.trackers import register_tracker
            register_tracker(self, persist)

        # ByteTrack éœ€è¦è¾ƒä½ç½®ä¿¡åº¦è¾“å…¥
        kwargs["conf"] = kwargs.get("conf") or 0.1
        kwargs["batch"] = kwargs.get("batch") or 1  # è§†é¢‘é»˜è®¤ batch=1
        kwargs["mode"] = "track"

        return self.predict(source=source, stream=stream, **kwargs)

    def val(
        self,
        validator=None,
        **kwargs: Any,
    ):
        """
        å¯¹æ¨¡å‹è¿›è¡ŒéªŒè¯ã€‚

        æ”¯æŒè‡ªå®šä¹‰éªŒè¯å™¨(validatorï¼‰ï¼Œæˆ–é»˜è®¤ä½¿ç”¨ä»»åŠ¡å¯¹åº”çš„éªŒè¯é€»è¾‘ã€‚
        å¯è‡ªå®šä¹‰æ•°æ®é›†è·¯å¾„ã€è¾“å…¥å°ºå¯¸ã€è®¾å¤‡ç­‰ã€‚

        å‚æ•°ï¼š
            validator: è‡ªå®šä¹‰éªŒè¯å™¨ç±»ã€‚
            kwargs: å…¶ä»–éªŒè¯å‚æ•°(dataã€imgszã€deviceã€batch ç­‰ï¼‰ã€‚

        è¿”å›ï¼š
            éªŒè¯æŒ‡æ ‡(å¦‚ mAPã€F1-score ç­‰ï¼‰ã€‚
        """
        custom = {"rect": True}  # é»˜è®¤çŸ©å½¢æ¨ç†
        args = {**self.overrides, **custom, **kwargs, "mode": "val"}

        validator = (validator or self._smart_load("validator"))(args=args, _callbacks=self.callbacks)
        validator(model=self.model)
        self.metrics = validator.metrics
        return validator.metrics

    def benchmark(self, data=None, format="", verbose=False, **kwargs: Any):
        """
        å¯¹æ¨¡å‹è¿›è¡ŒåŸºå‡†æ€§èƒ½æµ‹è¯•(Benchmarkï¼‰ã€‚

        è¯¥å‡½æ•°å°†æ¨¡å‹å¯¼å‡ºä¸ºä¸åŒæ ¼å¼(å¦‚ ONNXã€TensorRTã€CoreMLï¼‰å¹¶è¯„ä¼°å„è‡ªæ¨ç†é€Ÿåº¦ä¸ç²¾åº¦ã€‚

        å‚æ•°ï¼š
            data: æ•°æ®é›†è·¯å¾„(é»˜è®¤ None è¡¨ç¤ºä½¿ç”¨å†…ç½®æ•°æ®ï¼‰ã€‚
            format: æŒ‡å®šå¯¼å‡ºæ ¼å¼è¿›è¡Œå•ä¸€åŸºå‡†è¯„æµ‹(å¦‚ 'onnx'ï¼‰ã€‚
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ã€‚
            kwargs: å…¶ä»–å‚æ•°(å¦‚ imgsz, half, int8, device ç­‰ï¼‰ã€‚

        è¿”å›ï¼š
            dictï¼šå„æ ¼å¼æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡(æ¨ç†æ—¶é—´ã€mAPã€å‚æ•°é‡ç­‰ï¼‰ã€‚
        """
        self._check_is_pytorch_model()
        from ultralytics.utils.benchmarks import benchmark
        from .exporter import export_formats

        custom = {"verbose": False}
        args = {**DEFAULT_CFG_DICT, **self.model.args, **custom, **kwargs, "mode": "benchmark"}

        fmts = export_formats()
        export_args = set(dict(zip(fmts["Argument"], fmts["Arguments"])).get(format, [])) - {"batch"}
        export_kwargs = {k: v for k, v in args.items() if k in export_args}

        return benchmark(
            model=self,
            data=data,
            imgsz=args["imgsz"],
            device=args["device"],
            verbose=verbose,
            format=format,
            **export_kwargs,
        )

    def export(
        self,
        **kwargs: Any,
    ) -> str:
        """
        å¯¼å‡ºæ¨¡å‹è‡³å¤šç§æ ¼å¼ä»¥ä¾¿éƒ¨ç½²ã€‚

        æ”¯æŒå¯¼å‡ºåˆ° ONNXã€TensorRTã€TorchScriptã€CoreMLã€OpenVINO ç­‰ä¸»æµæ ¼å¼ï¼Œ
        å¯é€‰æ‹©åŠç²¾åº¦ (FP16)ã€æ•´å‹é‡åŒ– (INT8)ã€åŠ¨æ€å°ºå¯¸ç­‰æ¨¡å¼ã€‚

        å‚æ•°ï¼š
            kwargs: å¯¼å‡ºå‚æ•°ï¼Œä¾‹å¦‚ï¼š
                format: å¯¼å‡ºæ ¼å¼(å¦‚ 'onnx'ã€'engine'ã€'coreml'ï¼‰
                half: æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦
                int8: æ˜¯å¦ä½¿ç”¨ INT8 é‡åŒ–
                device: å¯¼å‡ºè®¾å¤‡
                simplify: æ˜¯å¦ç®€åŒ– ONNX å›¾
                workspace: TensorRT æœ€å¤§æ˜¾å­˜åˆ†é…
                nms: æ˜¯å¦æ·»åŠ éæå¤§å€¼æŠ‘åˆ¶æ¨¡å—

        è¿”å›ï¼š
            strï¼šå¯¼å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚
        """
        self._check_is_pytorch_model()
        from .exporter import Exporter

        custom = {
            "imgsz": self.model.args["imgsz"],
            "batch": 1,
            "data": None,
            "device": None,
            "verbose": False,
        }
        args = {**self.overrides, **custom, **kwargs, "mode": "export"}

        return Exporter(overrides=args, _callbacks=self.callbacks)(model=self.model)
    def train(
        self,
        trainer=None,
        **kwargs: Any,
    ):
        """
        ä½¿ç”¨æŒ‡å®šçš„æ•°æ®é›†ä¸é…ç½®è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

        æ”¯æŒè‡ªå®šä¹‰è®­ç»ƒå™¨(trainerï¼‰æˆ–é»˜è®¤çš„ YOLO è®­ç»ƒå™¨ã€‚
        å½“æ¨¡å‹è¿æ¥ Ultralytics HUB äº‘ç«¯æ—¶ï¼Œä¼šè‡ªåŠ¨åŒæ­¥è®­ç»ƒä¼šè¯å‚æ•°ã€‚
        æ”¯æŒä» checkpoint æ¢å¤è®­ç»ƒã€ä¿®æ”¹å‚æ•°ã€æˆ–è‡ªå®šä¹‰ä¼˜åŒ–å™¨ã€‚

        å‚æ•°ï¼š
            trainer: è‡ªå®šä¹‰è®­ç»ƒå™¨ç±»(å¯é€‰ï¼‰ã€‚
            kwargs: è®­ç»ƒç›¸å…³é…ç½®ï¼Œä¾‹å¦‚ï¼š
                - data: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
                - epochs: è®­ç»ƒè½®æ•°
                - batch: æ‰¹æ¬¡å¤§å°
                - imgsz: è¾“å…¥å›¾åƒå¤§å°
                - device: è¿è¡Œè®¾å¤‡(cuda / cpuï¼‰
                - optimizer: ä¼˜åŒ–å™¨ç±»å‹(å¦‚ SGD / AdamWï¼‰
                - lr0: åˆå§‹å­¦ä¹ ç‡
                - patience: æ—©åœè½®æ•°(æœªæå‡è‡ªåŠ¨ç»ˆæ­¢è®­ç»ƒï¼‰
                - resume: æ˜¯å¦ä»ä¸Šæ¬¡ checkpoint æ¢å¤è®­ç»ƒ

        è¿”å›ï¼š
            metrics: è‹¥è®­ç»ƒæˆåŠŸåˆ™è¿”å›éªŒè¯æŒ‡æ ‡(å¦‚ mAPã€Precisionã€Recallï¼‰ã€‚
        """
        self._check_is_pytorch_model()

        # è‹¥å­˜åœ¨ Ultralytics HUB ä¼šè¯ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨å…¶äº‘ç«¯é…ç½®
        if hasattr(self.session, "model") and self.session.model.id:
            if any(kwargs):
                LOGGER.warning("æ£€æµ‹åˆ° HUB è¿œç¨‹è®­ç»ƒï¼Œå·²å¿½ç•¥æœ¬åœ°è®­ç»ƒå‚æ•°ã€‚")
            kwargs = self.session.train_args

        # æ£€æŸ¥ pip æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬(é˜²æ­¢ä¾èµ–ä¸ä¸€è‡´ï¼‰
        checks.check_pip_update_available()

        # è‹¥ä¼ å…¥ pretrained å‚æ•°ï¼Œåˆ™åŠ è½½æƒé‡
        if isinstance(kwargs.get("pretrained", None), (str, Path)):
            self.load(kwargs["pretrained"])

        # è‹¥ cfg å­˜åœ¨ï¼Œåˆ™åŠ è½½é…ç½®æ–‡ä»¶ï¼›å¦åˆ™ä½¿ç”¨ overrides
        overrides = YAML.load(checks.check_yaml(kwargs["cfg"])) if kwargs.get("cfg") else self.overrides

        # é»˜è®¤å‚æ•°ï¼šç¡®ä¿ dataã€modelã€task ä¸€è‡´
        custom = {
            "data": overrides.get("data") or DEFAULT_CFG_DICT["data"] or TASK2DATA[self.task],
            "model": self.overrides["model"],
            "task": self.task,
        }

        # åˆå¹¶é…ç½®ï¼šä¼˜å…ˆçº§ä»å·¦åˆ°å³(é»˜è®¤ < overrides < kwargsï¼‰
        args = {**overrides, **custom, **kwargs, "mode": "train", "session": self.session}

        # è‹¥å¯ç”¨ resume æ¨¡å¼ï¼Œåˆ™ä» ckpt_path ç»§ç»­è®­ç»ƒ
        if args.get("resume"):
            args["resume"] = self.ckpt_path

        # åŠ è½½è®­ç»ƒå™¨
        self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)

        # è‹¥ä¸æ˜¯ resume æ¨¡å¼ï¼Œåˆ™æ„å»ºæ–°æ¨¡å‹
        if not args.get("resume"):
            self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)
            self.model = self.trainer.model

        # å¼€å§‹è®­ç»ƒ
        self.trainer.train()

        # è®­ç»ƒç»“æŸåæ›´æ–°æ¨¡å‹ä¸æŒ‡æ ‡
        if RANK in {-1, 0}:
            ckpt = self.trainer.best if self.trainer.best.exists() else self.trainer.last
            self.model, self.ckpt = load_checkpoint(ckpt)
            self.overrides = self._reset_ckpt_args(self.model.args)
            self.metrics = getattr(self.trainer.validator, "metrics", None)

        return self.metrics

    def tune(
        self,
        use_ray=False,
        iterations=10,
        *args: Any,
        **kwargs: Any,
    ):
        """
        è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜(Hyperparameter Tuningï¼‰ã€‚

        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
            1. å†…ç½® Tuner(é»˜è®¤ï¼‰
            2. Ray Tune(åˆ†å¸ƒå¼æœç´¢ï¼‰

        å‚æ•°ï¼š
            use_ray: æ˜¯å¦ä½¿ç”¨ Ray Tune è°ƒå‚(True ä¸ºåˆ†å¸ƒå¼æ¨¡å¼ï¼‰ã€‚
            iterations: è°ƒå‚è¿­ä»£æ¬¡æ•°ã€‚
            *args, **kwargs: å…¶ä»–ä¼ å…¥å‚æ•°ï¼Œå¦‚ï¼š
                - data: æ•°æ®é›†è·¯å¾„
                - epochs: æ¯æ¬¡å®éªŒè®­ç»ƒè½®æ•°
                - lr0, momentum, weight_decay ç­‰ä¼˜åŒ–å‚æ•°èŒƒå›´

        è¿”å›ï¼š
            dictï¼šæœ€ä½³å‚æ•°åŠå¯¹åº”æŒ‡æ ‡ç»“æœã€‚
        """
        self._check_is_pytorch_model()

        # è‹¥å¯ç”¨ Ray Tune æ¨¡å¼
        if use_ray:
            from ultralytics.utils.tuner import run_ray_tune
            return run_ray_tune(self, max_samples=iterations, *args, **kwargs)

        # å¦åˆ™ä½¿ç”¨å†…ç½®è°ƒå‚å™¨
        else:
            from .tuner import Tuner
            custom = {}
            args = {**self.overrides, **custom, **kwargs, "mode": "train"}
            return Tuner(args=args, _callbacks=self.callbacks)(model=self, iterations=iterations)
    def _apply(self, fn) -> Model:
        """
        å°†ç»™å®šå‡½æ•°åº”ç”¨åˆ°æ¨¡å‹çš„æ‰€æœ‰å¼ é‡(åŒ…æ‹¬éå‚æ•°å¼ é‡ï¼‰ã€‚

        ç”¨äºæ¨¡å‹è®¾å¤‡è¿ç§»ã€ç²¾åº¦å˜æ¢(å¦‚ .to('cuda')ã€.half()ï¼‰ç­‰æ“ä½œã€‚
        åŒæ—¶ä¼šé‡ç½® predictor(é˜²æ­¢è®¾å¤‡å˜æ›´å¯¼è‡´çš„ä¸Šä¸‹æ–‡é”™è¯¯ï¼‰ï¼Œ
        å¹¶æ›´æ–° overrides ä¸­çš„ device å‚æ•°ã€‚

        å‚æ•°ï¼š
            fn: å¾…åº”ç”¨çš„å‡½æ•°ï¼Œå¦‚ lambda t: t.cuda()ã€‚

        è¿”å›ï¼š
            Model: åº”ç”¨å‡½æ•°åçš„æ¨¡å‹å®ä¾‹ã€‚
        """
        self._check_is_pytorch_model()
        self = super()._apply(fn)
        self.predictor = None  # é‡ç½®é¢„æµ‹å™¨(è®¾å¤‡å¯èƒ½å·²æ”¹å˜ï¼‰
        self.overrides["device"] = self.device
        return self

    @property
    def names(self) -> dict[int, str]:
        """
        è·å–å½“å‰æ¨¡å‹çš„ç±»åˆ«åç§°æ˜ å°„ã€‚

        è¿”å›æ¨¡å‹çš„ç±»åˆ«å­—å…¸(index -> nameï¼‰ã€‚
        è‹¥ predictor å°šæœªåˆå§‹åŒ–ï¼Œä¼šå…ˆè‡ªåŠ¨åŠ è½½ predictorã€‚

        è¿”å›ï¼š
            dict: {ç±»åˆ«ç´¢å¼•: ç±»åˆ«åç§°}
        """
        from ultralytics.nn.autobackend import check_class_names

        if hasattr(self.model, "names"):
            return check_class_names(self.model.names)

        if not self.predictor:
            predictor = self._smart_load("predictor")(overrides=self.overrides, _callbacks=self.callbacks)
            predictor.setup_model(model=self.model, verbose=False)
            return predictor.model.names

        return self.predictor.model.names

    @property
    def device(self) -> torch.device:
        """
        è·å–å½“å‰æ¨¡å‹æ‰€åœ¨è®¾å¤‡(CPU æˆ– GPUï¼‰ã€‚

        è¿”å›ï¼š
            torch.device: å½“å‰æ¨¡å‹å‚æ•°æ‰€åœ¨è®¾å¤‡ã€‚
        """
        return next(self.model.parameters()).device if isinstance(self.model, torch.nn.Module) else None

    @property
    def transforms(self):
        """
        è·å–æ¨¡å‹ä½¿ç”¨çš„æ•°æ®é¢„å¤„ç†(transformsï¼‰ã€‚

        è¿”å›ï¼š
            transforms å¯¹è±¡(è‹¥å­˜åœ¨ï¼‰æˆ– Noneã€‚
        """
        return self.model.transforms if hasattr(self.model, "transforms") else None

    def add_callback(self, event: str, func) -> None:
        """
        ä¸ºæŒ‡å®šäº‹ä»¶æ³¨å†Œæ–°çš„å›è°ƒå‡½æ•°ã€‚

        å›è°ƒå‡½æ•°ç”¨äºåœ¨è®­ç»ƒ/éªŒè¯/æ¨ç†è¿‡ç¨‹çš„ç‰¹å®šé˜¶æ®µæ‰§è¡Œè‡ªå®šä¹‰é€»è¾‘ã€‚
        ä¾‹å¦‚ on_train_startã€on_epoch_endã€on_predict_end ç­‰ã€‚

        å‚æ•°ï¼š
            event: äº‹ä»¶åç§°(å­—ç¬¦ä¸²ï¼Œå¦‚ 'on_train_start'ï¼‰ã€‚
            func: å›è°ƒå‡½æ•°ã€‚

        ç¤ºä¾‹ï¼š
            >>> def on_train_start(trainer): print("è®­ç»ƒå¼€å§‹ï¼")
            >>> model.add_callback("on_train_start", on_train_start)
        """
        self.callbacks[event].append(func)

    def clear_callback(self, event: str) -> None:
        """
        æ¸…é™¤æŒ‡å®šäº‹ä»¶çš„æ‰€æœ‰å›è°ƒå‡½æ•°ã€‚

        è¯¥æ–¹æ³•ä¼šå°†æŸäº‹ä»¶ä¸‹çš„æ‰€æœ‰è‡ªå®šä¹‰åŠé»˜è®¤å›è°ƒå…¨éƒ¨ç§»é™¤ã€‚

        å‚æ•°ï¼š
            event: è¦æ¸…é™¤çš„äº‹ä»¶åç§°ã€‚

        ç¤ºä¾‹ï¼š
            >>> model.clear_callback("on_train_start")
        """
        self.callbacks[event] = []

    def reset_callbacks(self) -> None:
        """
        é‡ç½®æ‰€æœ‰å›è°ƒä¸ºé»˜è®¤è®¾ç½®ã€‚

        å°†æ‰€æœ‰äº‹ä»¶çš„å›è°ƒå‡½æ•°æ¢å¤ä¸º Ultralytics æ¡†æ¶å†…ç½®çš„é»˜è®¤å›è°ƒã€‚
        å½“è¿›è¡Œäº†å¤§é‡è‡ªå®šä¹‰å›è°ƒè°ƒè¯•åï¼Œå¯ç”¨æ­¤æ–¹æ³•å›åˆ°åŸå§‹çŠ¶æ€ã€‚
        """
        for event in callbacks.default_callbacks.keys():
            self.callbacks[event] = [callbacks.default_callbacks[event][0]]

    @staticmethod
    def _reset_ckpt_args(args: dict[str, Any]) -> dict[str, Any]:
        """
        åœ¨åŠ è½½ PyTorch æ¨¡å‹ checkpoint æ—¶é‡ç½®éƒ¨åˆ†å‚æ•°ã€‚

        ä»…ä¿ç•™å…³é”®å­—æ®µ(imgszã€dataã€taskã€single_clsï¼‰ï¼Œ
        é¿å…æ—§ checkpoint å‚æ•°å½±å“æ–°è®­ç»ƒã€‚

        å‚æ•°ï¼š
            args: åŸå§‹ checkpoint å‚æ•°å­—å…¸ã€‚

        è¿”å›ï¼š
            dict: ç²¾ç®€åçš„å‚æ•°å­—å…¸ã€‚
        """
        include = {"imgsz", "data", "task", "single_cls"}
        return {k: v for k, v in args.items() if k in include}

    def _smart_load(self, key: str):
        """
        æ™ºèƒ½åŠ è½½æ¨¡å‹ç»„ä»¶(å¦‚ modelã€trainerã€validatorã€predictorï¼‰ã€‚

        æ ¹æ®å½“å‰ä»»åŠ¡(detectã€segmentã€poseã€obb ç­‰ï¼‰è‡ªåŠ¨åŒ¹é…æ­£ç¡®çš„æ¨¡å—ã€‚
        è‹¥è¯¥ä»»åŠ¡ç±»å‹ä¸æ”¯æŒå¯¹åº”æ¨¡å¼ï¼Œä¼šæŠ›å‡ºå¼‚å¸¸ã€‚

        å‚æ•°ï¼š
            key: æ¨¡å—ç±»å‹('model' / 'trainer' / 'validator' / 'predictor'ï¼‰

        è¿”å›ï¼š
            å¯¹åº”æ¨¡å—ç±»ã€‚

        å¼‚å¸¸ï¼š
            NotImplementedError: è‹¥å½“å‰ä»»åŠ¡ä¸æ”¯æŒè¯¥æ¨¡å—ã€‚
        """
        try:
            return self.task_map[self.task][key]
        except Exception as e:
            name = self.__class__.__name__
            mode = inspect.stack()[1][3]
            raise NotImplementedError(f"æ¨¡å‹ '{name}' ä¸æ”¯æŒ '{self.task}' ä»»åŠ¡ä¸‹çš„ '{mode}' æ¨¡å¼ã€‚") from e

    @property
    def task_map(self) -> dict:
        """
        å®šä¹‰ä»»åŠ¡åˆ°æ¨¡å—(model/trainer/validator/predictorï¼‰çš„æ˜ å°„å…³ç³»ã€‚

        æ¯ä¸ªä»»åŠ¡(detectã€segmentã€classifyã€poseã€obb ç­‰ï¼‰
        å¯¹åº”ä¸€ç»„å®ç°ç±»ï¼Œæ¡†æ¶é€šè¿‡è¯¥æ˜ å°„åŠ¨æ€åŠ è½½åˆé€‚çš„ç»„ä»¶ã€‚

        è¿”å›ï¼š
            dict[str, dict[str, Any]]: ä»»åŠ¡å -> æ¨¡å—æ˜ å°„ã€‚
        """
        raise NotImplementedError("è¯·åœ¨å­ç±»ä¸­å®šä¹‰ task_map æ˜ å°„ï¼")

    def eval(self):
        """
        å°†æ¨¡å‹åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼(evaluation modeï¼‰ã€‚

        è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹ä¼šç¦ç”¨ dropoutï¼Œå¹¶å›ºå®š BatchNorm å‡å€¼æ–¹å·®ã€‚
        ç”¨äºæ¨ç†é˜¶æ®µçš„ç¨³å®šè¾“å‡ºã€‚

        è¿”å›ï¼š
            Model: å·²è®¾ç½®ä¸º eval æ¨¡å¼çš„æ¨¡å‹ã€‚
        """
        self.model.eval()
        return self

    def __getattr__(self, name):
        """
        å…è®¸ç›´æ¥é€šè¿‡ Model å®ä¾‹è®¿é—®åº•å±‚æ¨¡å‹çš„å±æ€§ã€‚

        è‹¥è®¿é—®å±æ€§åä¸º 'model'ï¼Œåˆ™è¿”å› self._modules['model']ï¼›
        å¦åˆ™ç›´æ¥ä»£ç†åˆ° self.model çš„å¯¹åº”å±æ€§ã€‚

        å‚æ•°ï¼š
            name: å±æ€§åã€‚

        è¿”å›ï¼š
            å¯¹åº”å±æ€§çš„å€¼ã€‚

        ç¤ºä¾‹ï¼š
            >>> model = YOLO("yolo11n.pt")
            >>> print(model.names)
            >>> print(model.stride)
        """
        return self._modules["model"] if name == "model" else getattr(self.model, name)

