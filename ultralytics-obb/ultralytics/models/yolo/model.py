# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from __future__ import annotations
from pathlib import Path
from typing import Any

import torch

from ultralytics.data.build import load_inference_source
from ultralytics.engine.model import Model
from ultralytics.models import yolo
from ultralytics.nn.tasks import (
    ClassificationModel,
    DetectionModel,
    OBBModel,
    PoseModel,
    SegmentationModel,
    WorldModel,
    YOLOEModel,
    YOLOESegModel,
)
from ultralytics.utils import ROOT, YAML


class YOLO(Model):
    """
    YOLO(You Only Look Once)ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚

    æœ¬ç±»ä¸º YOLO æ¨¡å‹æä¾›ç»Ÿä¸€æ¥å£ï¼Œä¼šæ ¹æ®æ¨¡å‹æ–‡ä»¶åè‡ªåŠ¨é€‰æ‹©ç‰¹å®šæ¨¡å‹ç±»å‹
    (å¦‚ YOLOWorldã€YOLOE)ï¼Œæ”¯æŒå¤šç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼š
    - ç›®æ ‡æ£€æµ‹(Detection)
    - å®ä¾‹åˆ†å‰²(Segmentation)
    - åˆ†ç±»(Classification)
    - å§¿æ€ä¼°è®¡(Pose Estimation)
    - æ—‹è½¬è¾¹ç•Œæ¡†æ£€æµ‹(OBB, Oriented Bounding Box)

    å±æ€§ï¼š
        model: å·²åŠ è½½çš„ YOLO æ¨¡å‹å®ä¾‹ã€‚
        task: æ¨¡å‹ä»»åŠ¡ç±»å‹(detect, segment, classify, pose, obb)ã€‚
        overrides: æ¨¡å‹é…ç½®è¦†ç›–é¡¹ã€‚

    æ–¹æ³•ï¼š
        __init__: åˆå§‹åŒ– YOLO æ¨¡å‹ï¼Œè‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹ã€‚
        task_map: å°†ä»»åŠ¡æ˜ å°„åˆ°ç›¸åº”çš„æ¨¡å‹ã€è®­ç»ƒå™¨ã€éªŒè¯å™¨å’Œé¢„æµ‹å™¨ã€‚

    ç¤ºä¾‹ï¼š
        åŠ è½½ YOLOv11n é¢„è®­ç»ƒæ£€æµ‹æ¨¡å‹ï¼š
        >>> model = YOLO("yolo11n.pt")

        åŠ è½½ YOLO11n åˆ†å‰²æ¨¡å‹ï¼š
        >>> model = YOLO("yolo11n-seg.pt")

        ä» YAML é…ç½®æ–‡ä»¶åˆå§‹åŒ–ï¼š
        >>> model = YOLO("yolo11n.yaml")
    """

    def __init__(self, model: str | Path = "yolo11n.pt", task: str | None = None, verbose: bool = False):
        """
        åˆå§‹åŒ– YOLO æ¨¡å‹ã€‚

        æ„é€ å‡½æ•°ä¼šæ ¹æ®æ¨¡å‹æ–‡ä»¶åè‡ªåŠ¨è¯†åˆ«ç±»å‹(å¦‚ YOLOWorldã€YOLOE)ï¼Œ
        å¹¶åŠ è½½å¯¹åº”çš„ç½‘ç»œç»“æ„ä¸é…ç½®ã€‚

        å‚æ•°ï¼š
            model (str | Path): æ¨¡å‹åç§°æˆ–è·¯å¾„ï¼Œä¾‹å¦‚ 'yolo11n.pt' æˆ– 'yolo11n.yaml'ã€‚
            task (str, å¯é€‰): æŒ‡å®šä»»åŠ¡ç±»å‹(detect, segment, classify, pose, obb)ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹ã€‚
            verbose (bool): æ˜¯å¦åœ¨åŠ è½½æ—¶æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ã€‚

        ç¤ºä¾‹ï¼š
            >>> from ultralytics import YOLO
            >>> model = YOLO("yolo11n.pt")         # åŠ è½½æ£€æµ‹æ¨¡å‹
            >>> model = YOLO("yolo11n-seg.pt")     # åŠ è½½åˆ†å‰²æ¨¡å‹
        """
        path = Path(model if isinstance(model, (str, Path)) else "")
        if "-world" in path.stem and path.suffix in {".pt", ".yaml", ".yml"}:  # YOLOWorld æ¨¡å‹
            new_instance = YOLOWorld(path, verbose=verbose)
            self.__class__ = type(new_instance)
            self.__dict__ = new_instance.__dict__
        elif "yoloe" in path.stem and path.suffix in {".pt", ".yaml", ".yml"}:  # YOLOE æ¨¡å‹
            new_instance = YOLOE(path, task=task, verbose=verbose)
            self.__class__ = type(new_instance)
            self.__dict__ = new_instance.__dict__
        else:
            # é»˜è®¤ YOLO åˆå§‹åŒ–
            super().__init__(model=model, task=task, verbose=verbose)
            if hasattr(self.model, "model") and "RTDETR" in self.model.model[-1]._get_name():  # æ£€æµ‹ RT-DETR ç»“æ„
                from ultralytics import RTDETR
                new_instance = RTDETR(self)
                self.__class__ = type(new_instance)
                self.__dict__ = new_instance.__dict__

    @property
    def task_map(self) -> dict[str, dict[str, Any]]:
        """å®šä¹‰ä»»åŠ¡ç±»å‹ä¸æ¨¡å‹ã€è®­ç»ƒå™¨ã€éªŒè¯å™¨ã€é¢„æµ‹å™¨çš„æ˜ å°„å…³ç³»ã€‚"""
        return {
            "classify": {
                "model": ClassificationModel,
                "trainer": yolo.classify.ClassificationTrainer,
                "validator": yolo.classify.ClassificationValidator,
                "predictor": yolo.classify.ClassificationPredictor,
            },
            "detect": {
                "model": DetectionModel,
                "trainer": yolo.detect.DetectionTrainer,
                "validator": yolo.detect.DetectionValidator,
                "predictor": yolo.detect.DetectionPredictor,
            },
            "segment": {
                "model": SegmentationModel,
                "trainer": yolo.segment.SegmentationTrainer,
                "validator": yolo.segment.SegmentationValidator,
                "predictor": yolo.segment.SegmentationPredictor,
            },
            "pose": {
                "model": PoseModel,
                "trainer": yolo.pose.PoseTrainer,
                "validator": yolo.pose.PoseValidator,
                "predictor": yolo.pose.PosePredictor,
            },
            "obb": {  # æ—‹è½¬æ¡†ä»»åŠ¡
                "model": OBBModel,
                "trainer": yolo.obb.OBBTrainer,
                "validator": yolo.obb.OBBValidator,
                "predictor": yolo.obb.OBBPredictor,
            },
        }


class YOLOWorld(Model):
    """
    YOLO-World å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚

    YOLO-World æ˜¯ä¸€ç§â€œå¼€æ”¾è¯æ±‡æ£€æµ‹â€æ¨¡å‹ï¼Œ
    å¯æ ¹æ®æ–‡æœ¬æè¿°æ£€æµ‹ç›®æ ‡ï¼Œè€Œæ— éœ€åœ¨ç‰¹å®šç±»åˆ«ä¸Šè®­ç»ƒã€‚
    å®ƒåœ¨ YOLO æ¶æ„ä¸Šæ‰©å±•äº†æ–‡æœ¬åµŒå…¥æ¨¡å—ï¼Œ
    æ”¯æŒå®æ—¶å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹ã€‚

    å±æ€§ï¼š
        model: å·²åŠ è½½çš„ YOLO-World æ¨¡å‹å®ä¾‹ã€‚
        task: å›ºå®šä¸º 'detect'ã€‚
        overrides: æ¨¡å‹é…ç½®è¦†ç›–é¡¹ã€‚

    ç¤ºä¾‹ï¼š
        >>> model = YOLOWorld("yolov8s-world.pt")
        >>> model.set_classes(["person", "car", "bicycle"])
    """

    def __init__(self, model: str | Path = "yolov8s-world.pt", verbose: bool = False) -> None:
        """
        åˆå§‹åŒ– YOLOv8-World æ¨¡å‹ã€‚

        å‚æ•°ï¼š
            model (str | Path): æ¨¡å‹è·¯å¾„(æ”¯æŒ .pt / .yaml)ã€‚
            verbose (bool): æ˜¯å¦æ‰“å°é¢å¤–ä¿¡æ¯ã€‚
        """
        super().__init__(model=model, task="detect", verbose=verbose)

        # å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰ç±»åˆ«ï¼Œåˆ™åŠ è½½é»˜è®¤ COCO ç±»åˆ«åç§°
        if not hasattr(self.model, "names"):
            self.model.names = YAML.load(ROOT / "cfg/datasets/coco8.yaml").get("names")

    @property
    def task_map(self) -> dict[str, dict[str, Any]]:
        """ä»»åŠ¡æ˜ å°„ï¼šå®šä¹‰æ£€æµ‹ä»»åŠ¡å¯¹åº”çš„ç±»ã€‚"""
        return {
            "detect": {
                "model": WorldModel,
                "validator": yolo.detect.DetectionValidator,
                "predictor": yolo.detect.DetectionPredictor,
                "trainer": yolo.world.WorldTrainer,
            }
        }

    def set_classes(self, classes: list[str]) -> None:
        """
        è®¾ç½®æ¨¡å‹æ£€æµ‹ç±»åˆ«ã€‚

        å‚æ•°ï¼š
            classes (list[str]): ç±»åˆ«åˆ—è¡¨ï¼Œä¾‹å¦‚ ["person", "car", "dog"]ã€‚
        """
        self.model.set_classes(classes)
        # è‹¥åŒ…å«èƒŒæ™¯ç±»ï¼Œåˆ™ç§»é™¤
        background = " "
        if background in classes:
            classes.remove(background)
        self.model.names = classes

        # åŒæ­¥é¢„æµ‹å™¨ç±»åˆ«å
        if self.predictor:
            self.predictor.model.names = classes


class YOLOE(Model):
    """
    YOLOE(Enhanced YOLO)æ¨¡å‹ã€‚

    YOLOE æ˜¯ YOLO çš„å¢å¼ºç‰ˆï¼Œ
    åŒæ—¶æ”¯æŒæ£€æµ‹ä¸å®ä¾‹åˆ†å‰²ï¼Œ
    å¹¶å¼•å…¥è§†è§‰ä¸æ–‡æœ¬ä½ç½®åµŒå…¥ã€è¯­ä¹‰æç¤ºã€è·¨æ¨¡æ€å¯¹é½ç­‰ç‰¹æ€§ã€‚

    å±æ€§ï¼š
        model: åŠ è½½çš„ YOLOE æ¨¡å‹å®ä¾‹ã€‚
        task: å½“å‰ä»»åŠ¡ç±»å‹(detect æˆ– segment)ã€‚
        overrides: æ¨¡å‹é…ç½®è¦†ç›–é¡¹ã€‚

    ç¤ºä¾‹ï¼š
        >>> model = YOLOE("yoloe-11s-seg.pt")
        >>> model.set_vocab(["person", "car", "dog"], ["person", "car", "dog"])
        >>> results = model.predict("image.jpg")
    """

    def __init__(self, model: str | Path = "yoloe-11s-seg.pt", task: str | None = None, verbose: bool = False) -> None:
        """åˆå§‹åŒ– YOLOE æ¨¡å‹ã€‚"""
        super().__init__(model=model, task=task, verbose=verbose)

    @property
    def task_map(self) -> dict[str, dict[str, Any]]:
        """ä»»åŠ¡æ˜ å°„ï¼šæ£€æµ‹ä¸åˆ†å‰²ä»»åŠ¡å¯¹åº”ç±»ã€‚"""
        return {
            "detect": {
                "model": YOLOEModel,
                "validator": yolo.yoloe.YOLOEDetectValidator,
                "predictor": yolo.detect.DetectionPredictor,
                "trainer": yolo.yoloe.YOLOETrainer,
            },
            "segment": {
                "model": YOLOESegModel,
                "validator": yolo.yoloe.YOLOESegValidator,
                "predictor": yolo.segment.SegmentationPredictor,
                "trainer": yolo.yoloe.YOLOESegTrainer,
            },
        }

    def get_text_pe(self, texts):
        """è·å–æ–‡æœ¬ä½ç½®åµŒå…¥ã€‚"""
        assert isinstance(self.model, YOLOEModel)
        return self.model.get_text_pe(texts)

    def get_visual_pe(self, img, visual):
        """
        è·å–å›¾åƒç‰¹å¾çš„è§†è§‰ä½ç½®åµŒå…¥ã€‚

        å‚æ•°ï¼š
            img (torch.Tensor): è¾“å…¥å›¾åƒã€‚
            visual (torch.Tensor): è§†è§‰ç‰¹å¾ã€‚

        è¿”å›ï¼š
            (torch.Tensor): è§†è§‰ä½ç½®åµŒå…¥ã€‚
        """
        assert isinstance(self.model, YOLOEModel)
        return self.model.get_visual_pe(img, visual)

    def set_vocab(self, vocab: list[str], names: list[str]) -> None:
        """
        è®¾ç½®æ¨¡å‹çš„è¯æ±‡è¡¨ä¸ç±»åˆ«åç§°ã€‚

        å‚æ•°ï¼š
            vocab (list[str]): æ¨¡å‹ä½¿ç”¨çš„è¯æ±‡ã€‚
            names (list[str]): ç±»åˆ«åç§°ã€‚
        """
        assert isinstance(self.model, YOLOEModel)
        self.model.set_vocab(vocab, names=names)

    def get_vocab(self, names):
        """æ ¹æ®ç±»åˆ«åè·å–è¯æ±‡è¡¨ã€‚"""
        assert isinstance(self.model, YOLOEModel)
        return self.model.get_vocab(names)

    def set_classes(self, classes: list[str], embeddings: torch.Tensor | None = None) -> None:
        """
        è®¾ç½®æ¨¡å‹æ£€æµ‹ç±»åˆ«åŠå…¶å¯¹åº”åµŒå…¥ã€‚

        å‚æ•°ï¼š
            classes (list[str]): ç±»åˆ«åˆ—è¡¨ã€‚
            embeddings (torch.Tensor): å¯¹åº”ç±»åˆ«çš„åµŒå…¥(å¯é€‰)ã€‚
        """
        assert isinstance(self.model, YOLOEModel)
        if embeddings is None:
            embeddings = self.get_text_pe(classes)
        self.model.set_classes(classes, embeddings)
        assert " " not in classes  # ä¸åº”åŒ…å«èƒŒæ™¯ç±»
        self.model.names = classes

        if self.predictor:
            self.predictor.model.names = classes

    def val(self, validator=None, load_vp: bool = False, refer_data: str | None = None, **kwargs):
        """
        ä½¿ç”¨æ–‡æœ¬æˆ–è§†è§‰æç¤ºè¿›è¡ŒéªŒè¯ã€‚

        å‚æ•°ï¼š
            validator (callable, å¯é€‰): è‡ªå®šä¹‰éªŒè¯å‡½æ•°ã€‚
            load_vp (bool): æ˜¯å¦åŠ è½½è§†è§‰æç¤ºã€‚
            refer_data (str, å¯é€‰): å¼•ç”¨æ•°æ®è·¯å¾„ã€‚
        è¿”å›ï¼š
            dict: éªŒè¯æŒ‡æ ‡ã€‚
        """
        custom = {"rect": not load_vp}
        args = {**self.overrides, **custom, **kwargs, "mode": "val"}
        validator = (validator or self._smart_load("validator"))(args=args, _callbacks=self.callbacks)
        validator(model=self.model, load_vp=load_vp, refer_data=refer_data)
        self.metrics = validator.metrics
        return validator.metrics

    def predict(self, source=None, stream: bool = False, visual_prompts: dict[str, list] = {},
                refer_image=None, predictor=yolo.yoloe.YOLOEVPDetectPredictor, **kwargs):
        """
        å¯¹å›¾åƒã€è§†é¢‘ã€ç›®å½•æˆ–æµè¿›è¡Œé¢„æµ‹ã€‚

        å‚æ•°ï¼š
            source (str | int | np.ndarray): è¾“å…¥æºã€‚
            stream (bool): æ˜¯å¦æµå¼è¾“å‡ºç»“æœã€‚
            visual_prompts (dict): åŒ…å« 'bboxes' ä¸ 'cls' çš„è§†è§‰æç¤ºã€‚
            refer_image: ç”¨ä½œè§†è§‰æç¤ºå‚è€ƒçš„å›¾åƒã€‚
            predictor: è‡ªå®šä¹‰é¢„æµ‹å™¨ã€‚
        è¿”å›ï¼š
            list | generator: é¢„æµ‹ç»“æœã€‚
        """
        if len(visual_prompts):
            assert "bboxes" in visual_prompts and "cls" in visual_prompts
            assert len(visual_prompts["bboxes"]) == len(visual_prompts["cls"])
            if type(self.predictor) is not predictor:
                self.predictor = predictor(
                    overrides={
                        "task": self.model.task,
                        "mode": "predict",
                        "save": False,
                        "verbose": refer_image is None,
                        "batch": 1,
                        "device": kwargs.get("device", None),
                        "half": kwargs.get("half", False),
                        "imgsz": kwargs.get("imgsz", self.overrides["imgsz"]),
                    },
                    _callbacks=self.callbacks,
                )

            num_cls = (
                max(len(set(c)) for c in visual_prompts["cls"])
                if isinstance(source, list) and refer_image is None
                else len(set(visual_prompts["cls"]))
            )
            self.model.model[-1].nc = num_cls
            self.model.names = [f"object{i}" for i in range(num_cls)]
            self.predictor.set_prompts(visual_prompts.copy())
            self.predictor.setup_model(model=self.model)

            if refer_image is None and source is not None:
                dataset = load_inference_source(source)
                if dataset.mode in {"video", "stream"}:
                    refer_image = next(iter(dataset))[1][0]
            if refer_image is not None:
                vpe = self.predictor.get_vpe(refer_image)
                self.model.set_classes(self.model.names, vpe)
                self.task = "segment" if isinstance(self.predictor, yolo.segment.SegmentationPredictor) else "detect"
                self.predictor = None
        elif isinstance(self.predictor, yolo.yoloe.YOLOEVPDetectPredictor):
            self.predictor = None

        return super().predict(source, stream, **kwargs)
