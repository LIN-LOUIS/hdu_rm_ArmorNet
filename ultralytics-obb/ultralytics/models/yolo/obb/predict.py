# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import torch

from ultralytics.engine.results import Results
from ultralytics.models.yolo.detect.predict import DetectionPredictor
from ultralytics.utils import DEFAULT_CFG, ops


class OBBPredictor(DetectionPredictor):
    """
    æ‰©å±•è‡ª DetectionPredictor çš„æ—‹è½¬è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰é¢„æµ‹ç±»ã€‚

    è¯¥é¢„æµ‹å™¨ä¸“ç”¨äºå¤„ç†æ—‹è½¬ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œå¯å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ¨ç†ï¼Œ
    è¾“å‡ºå¸¦æœ‰æ—‹è½¬è§’åº¦çš„ç›®æ ‡æ£€æµ‹ç»“æœã€‚

    å±æ€§ï¼š
        args (namespace): é¢„æµ‹å™¨çš„é…ç½®å‚æ•°ã€‚
        model (torch.nn.Module): å·²åŠ è½½çš„ YOLO-OBB æ¨¡å‹ã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics.utils import ASSETS
        >>> from ultralytics.models.yolo.obb import OBBPredictor
        >>> args = dict(model="yolo11n-obb.pt", source=ASSETS)
        >>> predictor = OBBPredictor(overrides=args)
        >>> predictor.predict_cli()
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """
        åˆå§‹åŒ– OBBPredictorï¼Œå¹¶å…è®¸ä¼ å…¥æ¨¡å‹æˆ–æ•°æ®é…ç½®çš„è‡ªå®šä¹‰è¦†ç›–å‚æ•°ã€‚

        å‚æ•°ï¼š
            cfg (dict, å¯é€‰): é¢„æµ‹å™¨çš„é»˜è®¤é…ç½®ã€‚
            overrides (dict, å¯é€‰): è‡ªå®šä¹‰é…ç½®é¡¹ï¼Œä¼šè¦†ç›–é»˜è®¤é…ç½®ã€‚
            _callbacks (list, å¯é€‰): åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­è§¦å‘çš„å›è°ƒå‡½æ•°åˆ—è¡¨ã€‚

        ç¤ºä¾‹ï¼š
            >>> from ultralytics.utils import ASSETS
            >>> from ultralytics.models.yolo.obb import OBBPredictor
            >>> args = dict(model="yolo11n-obb.pt", source=ASSETS)
            >>> predictor = OBBPredictor(overrides=args)
        """
        super().__init__(cfg, overrides, _callbacks)
        self.args.task = "obb"  # å°†ä»»åŠ¡ç±»å‹è®¾ç½®ä¸ºæ—‹è½¬æ¡†æ£€æµ‹ï¼ˆOriented Bounding Boxï¼‰

    def construct_result(self, pred, img, orig_img, img_path):
        """
        æ ¹æ®æ¨¡å‹é¢„æµ‹ç»“æœæ„å»ºç»“æœå¯¹è±¡ï¼ˆResultsï¼‰ã€‚

        å‚æ•°ï¼š
            pred (torch.Tensor): æ¨¡å‹çš„é¢„æµ‹è¾“å‡ºï¼Œå½¢çŠ¶ä¸º (N, 7)ï¼Œ
                å« [x, y, w, h, confidence, class_id, angle]ã€‚
            img (torch.Tensor): é¢„å¤„ç†åçš„å›¾åƒï¼Œå½¢çŠ¶ä¸º (B, C, H, W)ã€‚
            orig_img (np.ndarray): åŸå§‹è¾“å…¥å›¾åƒï¼ˆæœªç»è¿‡é¢„å¤„ç†ï¼‰ã€‚
            img_path (str): åŸå§‹å›¾åƒçš„è·¯å¾„ã€‚

        è¿”å›ï¼š
            (Results): åŒ…å«åŸå›¾ã€è·¯å¾„ã€ç±»åˆ«åç§°ä»¥åŠæ—‹è½¬è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰çš„ç»“æœå¯¹è±¡ã€‚
        """
        # å°†é¢„æµ‹æ¡†ä¸­çš„æ—‹è½¬è§’åº¦è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
        rboxes = ops.regularize_rboxes(torch.cat([pred[:, :4], pred[:, -1:]], dim=-1))
        # å°†é¢„æµ‹æ¡†ä»æ¨ç†å°ºå¯¸ç¼©æ”¾å›åŸå§‹å›¾åƒå°ºå¯¸
        rboxes[:, :4] = ops.scale_boxes(img.shape[2:], rboxes[:, :4], orig_img.shape, xywh=True)
        # æ‹¼æ¥ç½®ä¿¡åº¦ä¸ç±»åˆ«ä¿¡æ¯
        obb = torch.cat([rboxes, pred[:, 4:6]], dim=-1)
        # æ„å»ºç»“æœå¯¹è±¡
        return Results(orig_img, path=img_path, names=self.model.names, obb=obb)
